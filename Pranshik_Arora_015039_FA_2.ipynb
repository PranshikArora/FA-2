{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "irish-dublin",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-01T20:07:15.185005Z",
          "iopub.status.busy": "2021-06-01T20:07:15.184496Z",
          "iopub.status.idle": "2021-06-01T20:07:15.297502Z",
          "shell.execute_reply": "2021-06-01T20:07:15.296544Z",
          "shell.execute_reply.started": "2021-05-28T12:57:35.709083Z"
        },
        "papermill": {
          "duration": 0.147422,
          "end_time": "2021-06-01T20:07:15.297672",
          "exception": false,
          "start_time": "2021-06-01T20:07:15.150250",
          "status": "completed"
        },
        "tags": [],
        "id": "irish-dublin"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train = pd.read_csv('/input/commonlitreadabilityprize/train.csv')\n",
        "test = pd.read_csv('/input/commonlitreadabilityprize/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "built-discretion",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-01T20:07:15.364300Z",
          "iopub.status.busy": "2021-06-01T20:07:15.363577Z",
          "iopub.status.idle": "2021-06-01T20:07:15.366225Z",
          "shell.execute_reply": "2021-06-01T20:07:15.365830Z",
          "shell.execute_reply.started": "2021-05-28T12:57:35.838265Z"
        },
        "papermill": {
          "duration": 0.023692,
          "end_time": "2021-06-01T20:07:15.366329",
          "exception": false,
          "start_time": "2021-06-01T20:07:15.342637",
          "status": "completed"
        },
        "tags": [],
        "id": "built-discretion"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from glob import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from collections import defaultdict\n",
        "import gc\n",
        "gc.enable()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "official-festival",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-01T20:07:15.401019Z",
          "iopub.status.busy": "2021-06-01T20:07:15.400458Z",
          "iopub.status.idle": "2021-06-01T20:07:23.308289Z",
          "shell.execute_reply": "2021-06-01T20:07:23.307382Z",
          "shell.execute_reply.started": "2021-05-28T12:57:35.847953Z"
        },
        "papermill": {
          "duration": 7.927377,
          "end_time": "2021-06-01T20:07:23.308430",
          "exception": false,
          "start_time": "2021-06-01T20:07:15.381053",
          "status": "completed"
        },
        "tags": [],
        "id": "official-festival"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.optimizer import Optimizer\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.utils.data import (\n",
        "    Dataset, DataLoader, \n",
        "    SequentialSampler, RandomSampler\n",
        ")\n",
        "from transformers import RobertaConfig\n",
        "from transformers import (\n",
        "    get_cosine_schedule_with_warmup, \n",
        "    get_cosine_with_hard_restarts_schedule_with_warmup\n",
        ")\n",
        "from transformers import RobertaTokenizer\n",
        "from transformers import RobertaModel\n",
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm, trange"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "encouraging-stationery",
      "metadata": {
        "papermill": {
          "duration": 0.015052,
          "end_time": "2021-06-01T20:07:23.339441",
          "exception": false,
          "start_time": "2021-06-01T20:07:23.324389",
          "status": "completed"
        },
        "tags": [],
        "id": "encouraging-stationery"
      },
      "source": [
        "**Converting Examples to Features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "opening-slovakia",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-01T20:07:23.376040Z",
          "iopub.status.busy": "2021-06-01T20:07:23.375256Z",
          "iopub.status.idle": "2021-06-01T20:07:23.377719Z",
          "shell.execute_reply": "2021-06-01T20:07:23.377310Z",
          "shell.execute_reply.started": "2021-05-28T12:57:43.159271Z"
        },
        "papermill": {
          "duration": 0.023188,
          "end_time": "2021-06-01T20:07:23.377828",
          "exception": false,
          "start_time": "2021-06-01T20:07:23.354640",
          "status": "completed"
        },
        "tags": [],
        "id": "opening-slovakia"
      },
      "outputs": [],
      "source": [
        "def convert_examples_to_features(data, tokenizer, max_len, is_test=False):\n",
        "    data = data.replace('\\n', '')\n",
        "    tok = tokenizer.encode_plus(\n",
        "        data, \n",
        "        max_length=max_len, \n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_token_type_ids=True\n",
        "    )\n",
        "    curr_sent = {}\n",
        "    padding_length = max_len - len(tok['input_ids'])\n",
        "    curr_sent['input_ids'] = tok['input_ids'] + ([0] * padding_length)\n",
        "    curr_sent['token_type_ids'] = tok['token_type_ids'] + \\\n",
        "        ([0] * padding_length)\n",
        "    curr_sent['attention_mask'] = tok['attention_mask'] + \\\n",
        "        ([0] * padding_length)\n",
        "    return curr_sent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "occupational-yesterday",
      "metadata": {
        "papermill": {
          "duration": 0.014731,
          "end_time": "2021-06-01T20:07:23.407350",
          "exception": false,
          "start_time": "2021-06-01T20:07:23.392619",
          "status": "completed"
        },
        "tags": [],
        "id": "occupational-yesterday"
      },
      "source": [
        "**Retriving the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "informational-athens",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-01T20:07:23.446823Z",
          "iopub.status.busy": "2021-06-01T20:07:23.446084Z",
          "iopub.status.idle": "2021-06-01T20:07:23.448713Z",
          "shell.execute_reply": "2021-06-01T20:07:23.448307Z",
          "shell.execute_reply.started": "2021-05-28T12:57:43.167729Z"
        },
        "papermill": {
          "duration": 0.0264,
          "end_time": "2021-06-01T20:07:23.448817",
          "exception": false,
          "start_time": "2021-06-01T20:07:23.422417",
          "status": "completed"
        },
        "tags": [],
        "id": "informational-athens"
      },
      "outputs": [],
      "source": [
        "class DatasetRetriever(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len, is_test=False):\n",
        "        self.data = data\n",
        "        self.excerpts = self.data.excerpt.values.tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.is_test = is_test\n",
        "        self.max_len = max_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        if not self.is_test:\n",
        "            excerpt, label = self.excerpts[item], self.targets[item]\n",
        "            features = convert_examples_to_features(\n",
        "                excerpt, self.tokenizer, \n",
        "                self.max_len, self.is_test\n",
        "            )\n",
        "            return {\n",
        "                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
        "                'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
        "                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
        "                'label':torch.tensor(label, dtype=torch.double),\n",
        "            }\n",
        "        else:\n",
        "            excerpt = self.excerpts[item]\n",
        "            features = convert_examples_to_features(\n",
        "                excerpt, self.tokenizer, \n",
        "                self.max_len, self.is_test\n",
        "            )\n",
        "            return {\n",
        "                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
        "                'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
        "                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
        "            }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "renewable-spoke",
      "metadata": {
        "papermill": {
          "duration": 0.014655,
          "end_time": "2021-06-01T20:07:23.478432",
          "exception": false,
          "start_time": "2021-06-01T20:07:23.463777",
          "status": "completed"
        },
        "tags": [],
        "id": "renewable-spoke"
      },
      "source": [
        "**Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "silver-rebel",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-01T20:07:23.521291Z",
          "iopub.status.busy": "2021-06-01T20:07:23.520605Z",
          "iopub.status.idle": "2021-06-01T20:07:23.523967Z",
          "shell.execute_reply": "2021-06-01T20:07:23.523495Z",
          "shell.execute_reply.started": "2021-05-28T12:57:43.182037Z"
        },
        "papermill": {
          "duration": 0.030725,
          "end_time": "2021-06-01T20:07:23.524066",
          "exception": false,
          "start_time": "2021-06-01T20:07:23.493341",
          "status": "completed"
        },
        "tags": [],
        "id": "silver-rebel"
      },
      "outputs": [],
      "source": [
        "class CommonLitModel(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        model_name, \n",
        "        config,  \n",
        "        multisample_dropout=False,\n",
        "        output_hidden_states=False\n",
        "    ):\n",
        "        super(CommonLitModel, self).__init__()\n",
        "        self.config = config\n",
        "        self.roberta = RobertaModel.from_pretrained(\n",
        "            model_name, \n",
        "            output_hidden_states=output_hidden_states\n",
        "        )\n",
        "        self.layer_norm = nn.LayerNorm(config.hidden_size)\n",
        "        if multisample_dropout:\n",
        "            self.dropouts = nn.ModuleList([\n",
        "                nn.Dropout(0.5) for _ in range(5)\n",
        "            ])\n",
        "        else:\n",
        "            self.dropouts = nn.ModuleList([nn.Dropout(0.3)])\n",
        "        self.regressor = nn.Linear(config.hidden_size, 1)\n",
        "        self._init_weights(self.layer_norm)\n",
        "        self._init_weights(self.regressor)\n",
        " \n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        " \n",
        "    def forward(\n",
        "        self, \n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        labels=None\n",
        "    ):\n",
        "        outputs = self.roberta(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "        sequence_output = outputs[1]\n",
        "        sequence_output = self.layer_norm(sequence_output)\n",
        " \n",
        "        # multi-sample dropout\n",
        "        for i, dropout in enumerate(self.dropouts):\n",
        "            if i == 0:\n",
        "                logits = self.regressor(dropout(sequence_output))\n",
        "            else:\n",
        "                logits += self.regressor(dropout(sequence_output))\n",
        "        \n",
        "        logits /= len(self.dropouts)\n",
        " \n",
        "        # calculate loss\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fn = torch.nn.MSELoss()\n",
        "            logits = logits.view(-1).to(labels.dtype)\n",
        "            loss = torch.sqrt(loss_fn(logits, labels.view(-1)))\n",
        "        \n",
        "        output = (logits,) + outputs[1:]\n",
        "        return ((loss,) + output) if loss is not None else output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exotic-working",
      "metadata": {
        "papermill": {
          "duration": 0.014992,
          "end_time": "2021-06-01T20:07:23.554177",
          "exception": false,
          "start_time": "2021-06-01T20:07:23.539185",
          "status": "completed"
        },
        "tags": [],
        "id": "exotic-working"
      },
      "source": [
        "**Utils**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "classified-former",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-01T20:07:23.589820Z",
          "iopub.status.busy": "2021-06-01T20:07:23.589263Z",
          "iopub.status.idle": "2021-06-01T20:07:23.592510Z",
          "shell.execute_reply": "2021-06-01T20:07:23.592891Z",
          "shell.execute_reply.started": "2021-05-28T12:57:43.200304Z"
        },
        "papermill": {
          "duration": 0.02372,
          "end_time": "2021-06-01T20:07:23.593009",
          "exception": false,
          "start_time": "2021-06-01T20:07:23.569289",
          "status": "completed"
        },
        "tags": [],
        "id": "classified-former"
      },
      "outputs": [],
      "source": [
        "def make_model(model_name, num_labels=1):\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "    config = RobertaConfig.from_pretrained(model_name)\n",
        "    config.update({'num_labels':num_labels})\n",
        "    model = CommonLitModel(model_name, config=config)\n",
        "    return model, tokenizer\n",
        "\n",
        "def make_loader(\n",
        "    data, \n",
        "    tokenizer, \n",
        "    max_len,\n",
        "    batch_size,\n",
        "):\n",
        "    \n",
        "    test_dataset = DatasetRetriever(data, tokenizer, max_len, is_test=True)\n",
        "    test_sampler = SequentialSampler(test_dataset)\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, \n",
        "        batch_size=batch_size // 2, \n",
        "        sampler=test_sampler, \n",
        "        pin_memory=False, \n",
        "        drop_last=False, \n",
        "        num_workers=0\n",
        "    )\n",
        "\n",
        "    return test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vietnamese-negotiation",
      "metadata": {
        "papermill": {
          "duration": 0.014892,
          "end_time": "2021-06-01T20:07:23.622746",
          "exception": false,
          "start_time": "2021-06-01T20:07:23.607854",
          "status": "completed"
        },
        "tags": [],
        "id": "vietnamese-negotiation"
      },
      "source": [
        "**Evaluator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "single-paintball",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-01T20:07:23.660039Z",
          "iopub.status.busy": "2021-06-01T20:07:23.659367Z",
          "iopub.status.idle": "2021-06-01T20:07:23.662117Z",
          "shell.execute_reply": "2021-06-01T20:07:23.661668Z",
          "shell.execute_reply.started": "2021-05-28T12:57:52.206134Z"
        },
        "papermill": {
          "duration": 0.02477,
          "end_time": "2021-06-01T20:07:23.662237",
          "exception": false,
          "start_time": "2021-06-01T20:07:23.637467",
          "status": "completed"
        },
        "tags": [],
        "id": "single-paintball"
      },
      "outputs": [],
      "source": [
        "class Evaluator:\n",
        "    def __init__(self, model, scalar=None):\n",
        "        self.model = model\n",
        "        self.scalar = scalar\n",
        "\n",
        "    def evaluate(self, data_loader, tokenizer):\n",
        "        preds = []\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch_data in enumerate(data_loader):\n",
        "                input_ids, attention_mask, token_type_ids = batch_data['input_ids'], \\\n",
        "                    batch_data['attention_mask'], batch_data['token_type_ids']\n",
        "                input_ids, attention_mask, token_type_ids = input_ids.cuda(), \\\n",
        "                    attention_mask.cuda(), token_type_ids.cuda()\n",
        "                \n",
        "                if self.scalar is not None:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        outputs = self.model(\n",
        "                            input_ids=input_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "                            token_type_ids=token_type_ids\n",
        "                        )\n",
        "                else:\n",
        "                    outputs = self.model(\n",
        "                        input_ids=input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        token_type_ids=token_type_ids\n",
        "                    )\n",
        "                \n",
        "                logits = outputs[0].detach().cpu().numpy().squeeze().tolist()\n",
        "                preds += logits\n",
        "        return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "atlantic-archive",
      "metadata": {
        "papermill": {
          "duration": 0.014642,
          "end_time": "2021-06-01T20:07:23.691642",
          "exception": false,
          "start_time": "2021-06-01T20:07:23.677000",
          "status": "completed"
        },
        "tags": [],
        "id": "atlantic-archive"
      },
      "source": [
        "**Config**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "structural-excess",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-01T20:07:23.728097Z",
          "iopub.status.busy": "2021-06-01T20:07:23.727355Z",
          "iopub.status.idle": "2021-06-01T20:07:23.730052Z",
          "shell.execute_reply": "2021-06-01T20:07:23.729522Z",
          "shell.execute_reply.started": "2021-05-28T12:57:53.97421Z"
        },
        "papermill": {
          "duration": 0.02363,
          "end_time": "2021-06-01T20:07:23.730151",
          "exception": false,
          "start_time": "2021-06-01T20:07:23.706521",
          "status": "completed"
        },
        "tags": [],
        "id": "structural-excess"
      },
      "outputs": [],
      "source": [
        " def config(fold, model_name, load_model_path):\n",
        "    torch.manual_seed(2021)\n",
        "    torch.cuda.manual_seed(2021)\n",
        "    torch.cuda.manual_seed_all(2021)\n",
        "    \n",
        "    max_len = 250\n",
        "    batch_size = 8\n",
        "\n",
        "    model, tokenizer = make_model(\n",
        "        model_name=model_name, \n",
        "        num_labels=1\n",
        "    )\n",
        "    model.load_state_dict(\n",
        "        torch.load(f'{load_model_path}/model{fold}.bin')\n",
        "    )\n",
        "    test_loader = make_loader(\n",
        "        test, tokenizer, max_len=max_len,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    if torch.cuda.device_count() >= 1:\n",
        "        print('Model pushed to {} GPU(s), type {}.'.format(\n",
        "            torch.cuda.device_count(), \n",
        "            torch.cuda.get_device_name(0))\n",
        "        )\n",
        "        model = model.cuda() \n",
        "    else:\n",
        "        raise ValueError('CPU training is not supported')\n",
        "\n",
        "    # scaler = torch.cuda.amp.GradScaler()\n",
        "    scaler = None\n",
        "    return (\n",
        "        model, tokenizer, \n",
        "        test_loader, scaler\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "embedded-montreal",
      "metadata": {
        "papermill": {
          "duration": 0.01465,
          "end_time": "2021-06-01T20:07:23.759942",
          "exception": false,
          "start_time": "2021-06-01T20:07:23.745292",
          "status": "completed"
        },
        "tags": [],
        "id": "embedded-montreal"
      },
      "source": [
        "**Run**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "welsh-temperature",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-01T20:07:23.795221Z",
          "iopub.status.busy": "2021-06-01T20:07:23.794519Z",
          "iopub.status.idle": "2021-06-01T20:07:23.796838Z",
          "shell.execute_reply": "2021-06-01T20:07:23.797205Z",
          "shell.execute_reply.started": "2021-05-28T12:57:57.1208Z"
        },
        "papermill": {
          "duration": 0.022519,
          "end_time": "2021-06-01T20:07:23.797322",
          "exception": false,
          "start_time": "2021-06-01T20:07:23.774803",
          "status": "completed"
        },
        "tags": [],
        "id": "welsh-temperature"
      },
      "outputs": [],
      "source": [
        "def run(fold=0, model_name=None, load_model_path=None):\n",
        "    model, tokenizer, \\\n",
        "        test_loader, scaler = config(fold, model_name, load_model_path)\n",
        "    \n",
        "    import time\n",
        "\n",
        "    evaluator = Evaluator(model, scaler)\n",
        "\n",
        "    test_time_list = []\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    tic1 = time.time()\n",
        "\n",
        "    preds = evaluator.evaluate(test_loader, tokenizer)\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    tic2 = time.time() \n",
        "    test_time_list.append(tic2 - tic1)\n",
        "    \n",
        "    del model, tokenizer, test_loader, scaler\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "intense-harassment",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-01T20:07:23.833259Z",
          "iopub.status.busy": "2021-06-01T20:07:23.832765Z",
          "iopub.status.idle": "2021-06-01T20:12:12.400532Z",
          "shell.execute_reply": "2021-06-01T20:12:12.400975Z",
          "shell.execute_reply.started": "2021-05-28T12:59:26.446753Z"
        },
        "papermill": {
          "duration": 288.588654,
          "end_time": "2021-06-01T20:12:12.401132",
          "exception": false,
          "start_time": "2021-06-01T20:07:23.812478",
          "status": "completed"
        },
        "tags": [],
        "id": "intense-harassment",
        "outputId": "199a8b8b-db62-4515-ae17-fa328cecb033"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 1/5 [01:22<05:29, 82.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 2/5 [02:14<03:14, 64.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 3/5 [03:06<01:57, 58.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 4/5 [03:58<00:56, 56.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [04:48<00:00, 57.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 32s, sys: 19.4 s, total: 1min 51s\n",
            "Wall time: 4min 48s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "pred_df1 = pd.DataFrame()\n",
        "pred_df2 = pd.DataFrame()\n",
        "pred_df3 = pd.DataFrame()\n",
        "for fold in tqdm(range(5)):\n",
        "    pred_df1[f'fold{fold}'] = run(fold, '/input/roberta-base/', '/input/commonlit-roberta-base-i/')\n",
        "    pred_df2[f'fold{fold+5}'] = run(fold, '/input/robertalarge/', '/input/roberta-large-itptfit/')\n",
        "    pred_df3[f'fold{fold+10}'] = run(fold, '/input/robertalarge/', '/input/commonlit-roberta-large-ii/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "prostate-executive",
      "metadata": {
        "papermill": {
          "duration": 0.02092,
          "end_time": "2021-06-01T20:12:12.443670",
          "exception": false,
          "start_time": "2021-06-01T20:12:12.422750",
          "status": "completed"
        },
        "tags": [],
        "id": "prostate-executive"
      },
      "source": [
        "**Submission**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vertical-healthcare",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-01T20:12:12.496644Z",
          "iopub.status.busy": "2021-06-01T20:12:12.496155Z",
          "iopub.status.idle": "2021-06-01T20:12:12.972515Z",
          "shell.execute_reply": "2021-06-01T20:12:12.971573Z",
          "shell.execute_reply.started": "2021-05-28T13:23:05.546803Z"
        },
        "papermill": {
          "duration": 0.507851,
          "end_time": "2021-06-01T20:12:12.972662",
          "exception": false,
          "start_time": "2021-06-01T20:12:12.464811",
          "status": "completed"
        },
        "tags": [],
        "id": "vertical-healthcare"
      },
      "outputs": [],
      "source": [
        "sub = pd.read_csv('/input/commonlitreadabilityprize/sample_submission.csv')\n",
        "sub['target'] = (pred_df2.mean(axis=1)*0.5) + (pred_df1.mean(axis=1)*0.3) + (pred_df3.mean(axis=1) * 0.2).values.tolist()\n",
        "sub.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "joint-condition",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-01T20:12:13.075621Z",
          "iopub.status.busy": "2021-06-01T20:12:13.075142Z",
          "iopub.status.idle": "2021-06-01T20:12:13.084841Z",
          "shell.execute_reply": "2021-06-01T20:12:13.084441Z",
          "shell.execute_reply.started": "2021-05-28T13:23:09.40502Z"
        },
        "papermill": {
          "duration": 0.041875,
          "end_time": "2021-06-01T20:12:13.084954",
          "exception": false,
          "start_time": "2021-06-01T20:12:13.043079",
          "status": "completed"
        },
        "tags": [],
        "id": "joint-condition",
        "outputId": "1bbc0ec3-9980-4a31-ea4e-45e9a5bbc7ad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c0f722661</td>\n",
              "      <td>-0.424239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f0953f0a5</td>\n",
              "      <td>-0.552417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0df072751</td>\n",
              "      <td>-0.480693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>04caf4e0c</td>\n",
              "      <td>-2.409766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0e63f8bea</td>\n",
              "      <td>-1.869201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12537fe78</td>\n",
              "      <td>-1.139890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>965e592c0</td>\n",
              "      <td>0.154946</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id    target\n",
              "0  c0f722661 -0.424239\n",
              "1  f0953f0a5 -0.552417\n",
              "2  0df072751 -0.480693\n",
              "3  04caf4e0c -2.409766\n",
              "4  0e63f8bea -1.869201\n",
              "5  12537fe78 -1.139890\n",
              "6  965e592c0  0.154946"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "greenhouse-response",
      "metadata": {
        "papermill": {
          "duration": 0.021077,
          "end_time": "2021-06-01T20:12:13.127324",
          "exception": false,
          "start_time": "2021-06-01T20:12:13.106247",
          "status": "completed"
        },
        "tags": [],
        "id": "greenhouse-response"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 307.837859,
      "end_time": "2021-06-01T20:12:15.802715",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-06-01T20:07:07.964856",
      "version": "2.3.3"
    },
    "colab": {
      "name": "Pranshik_Arora_015039_FA_2.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}